{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fd79a-c7ba-45b4-9144-c5a7613dfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rdflib\n",
    "!pip install opendatasets\n",
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd61e7-b325-43f8-ab3a-6d78049d9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import FOAF, SKOS, RDF, RDFS, XSD, OWL\n",
    "import opendatasets as od\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15142776-4111-4fcd-b314-b9cf65ddf4be",
   "metadata": {},
   "source": [
    "## Download the datasets from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f207379-bbe9-4cf8-92e7-832f237db7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "od.download('https://www.kaggle.com/datasets/nobelfoundation/nobel-laureates')\n",
    "od.download('https://www.kaggle.com/datasets/xabirhasan/journal-ranking-dataset')\n",
    "od.download('https://www.kaggle.com/datasets/nechbamohammed/research-papers-dataset')\n",
    "# TODO download the other ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc39b1-f7d6-4b7e-bffc-79f64b558795",
   "metadata": {},
   "source": [
    "## Read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb7ed7-dc84-4245-a6cd-ccc8811c1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nobels = pd.read_csv('nobel-laureates/archive.csv')\n",
    "nobels.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = pd.read_csv('journal-ranking-dataset/journal_ranking_data.csv')\n",
    "journals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a623c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = pd.read_csv('research-papers-dataset/dblp-v10.csv')\n",
    "papers.info()\n",
    "papers.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159600cc-3679-4eb2-b3c1-3cc55269b0a5",
   "metadata": {},
   "source": [
    "## Parse our ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44be0f4-e6f3-4b2c-9fe2-4babce986daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph()\n",
    "graph.parse('nobelOntology.ttl', format='turtle')\n",
    "graph.parse('http://eulersharp.sourceforge.net/2003/03swap/countries', format='turtle')\n",
    "\n",
    "NO = Namespace('http://www.semanticweb.org/a3d/ontologies/2024/10/nobelOntology/')\n",
    "JUR = Namespace('http://sweet.jpl.nasa.gov/2.3/humanJurisdiction.owl#')\n",
    "\n",
    "# binding prefixes to URIs\n",
    "graph.bind('nobel', NO)\n",
    "graph.bind('jur', JUR)\n",
    "\n",
    "for ns_prefix, namespace in graph.namespaces():\n",
    "    print('{}: {}'.format(ns_prefix, namespace))\n",
    "\n",
    "for s, p, o in graph.triples((None, RDF.type, JUR.Country)):\n",
    "    print(f\"{s} is a country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb9785b-5d59-45b9-a29a-858309ef222d",
   "metadata": {},
   "source": [
    "## Populate the graph with nobel-laureates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc094af0-138d-41d4-9b69-f2f5816ba400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, unicodedata, html, re\n",
    "import topic_extraction\n",
    "\n",
    "def normalize_name(raw_name):\n",
    "    name = html.unescape(raw_name)\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('ascii')\n",
    "    uri_name = name.replace(',', '')\n",
    "    uri_name = uri_name.replace('-', ' ')\n",
    "    uri_name = ''.join(x for x in uri_name.title() if not x.isspace())\n",
    "    return (name, uri_name)\n",
    "\n",
    "def handle_city(raw_city):\n",
    "    (city_name, uri_city_name) = normalize_name(raw_city)\n",
    "    city = URIRef(NO[uri_city_name])\n",
    "    if (city, RDF.type, NO.City) not in graph: # new city\n",
    "        graph.add((city, RDF.type, NO.City))\n",
    "        graph.add((city, FOAF.name, Literal(city_name, datatype=XSD.string)))\n",
    "    return city\n",
    "\n",
    "def handle_org(raw_org):\n",
    "    (org_name, uri_org_name) = normalize_name(raw_org)\n",
    "    org = URIRef(NO[uri_org_name])\n",
    "    if (org, RDF.type, FOAF.Organization) not in graph: # new organization\n",
    "        graph.add((org, RDF.type, FOAF.Organization))\n",
    "        graph.add((org, FOAF.name, Literal(org_name, datatype=XSD.string)))\n",
    "    return org\n",
    "\n",
    "def handle_city_country(country_name):\n",
    "    # special cases\n",
    "\n",
    "    if country_name == 'United States of America':\n",
    "        country_name = 'United States'\n",
    "    if country_name == 'Scotland' or country_name == 'Northern Ireland':\n",
    "        country_name = 'United Kingdom'\n",
    "    if country_name == 'Guadeloupe Island':\n",
    "        country_name = 'Guadeloupe'\n",
    "    if country_name == 'East Timor':\n",
    "        country_name = 'Timor-Leste'\n",
    "    if country_name == 'East Germany' or country_name == 'Federal Republic of Germany':\n",
    "        country_name = 'Germany'\n",
    "    if country_name == 'Union of Soviet Socialist Republics':\n",
    "        country_name = 'Russian Federation'\n",
    "    if country_name == 'Czechoslovakia':\n",
    "        country_name = 'Czech Republic'\n",
    "    if country_name == 'Vietnam':\n",
    "        country_name = 'Viet Nam'\n",
    "    \n",
    "    # Regex pattern to capture content inside parentheses\n",
    "    pattern = r\"\\((.*?)\\)\"\n",
    "    match = re.findall(pattern, country_name)\n",
    "    if len(match) != 0:\n",
    "        country_name = match[0]\n",
    "\n",
    "    if country_name == 'Republic of Macedonia':\n",
    "        country_name = 'Macedonia, the former Yugoslav Republic of'\n",
    "    if country_name == 'South Korea':\n",
    "        country_name = 'Korea, Republic of'\n",
    "    if country_name == \"People's Republic of China\":\n",
    "        country_name = 'China'\n",
    "    if country_name == 'then Germany, now France':\n",
    "        country_name = 'France'\n",
    "    \n",
    "    country_query = f'''\n",
    "    SELECT ?country\n",
    "    WHERE {{\n",
    "        ?country rdf:type jur:Country;\n",
    "                foaf:name ?name.\n",
    "        FILTER(REGEX(?name, \"{country_name}\"))\n",
    "    }}'''\n",
    "\n",
    "    qres = graph.query(country_query)\n",
    "    if (len(qres) == 0):\n",
    "        print('Country not found: {}'.format(country_name))\n",
    "        return None\n",
    "\n",
    "    return qres\n",
    "\n",
    "\n",
    "for index, row in nobels.iterrows():\n",
    "    nobel = URIRef(NO[row['Category'] + str(row['Year'])]) # the URI will be nobelNamespace + Category + Year\n",
    "    graph.add((nobel, RDF.type, NO.NobelPrize))\n",
    "    graph.add((nobel, NO.hasYear, Literal(row['Year'], datatype=XSD.gYear)))\n",
    "    graph.add((nobel, NO.hasNobelCategory, Literal(row['Category'], datatype=XSD.string)))\n",
    "\n",
    "    # handle Prize Share\n",
    "    prizeShare = str(row['Prize Share']).split('/')\n",
    "    if (nobel, NO.hasPrizeShare, None) not in graph:\n",
    "        graph.add((nobel, NO.hasPrizeShare, Literal(prizeShare[1], datatype=XSD.integer)))\n",
    "\n",
    "    # handle Motivation\n",
    "    if ((nobel, NO.hasMotivationTopics, None) not in graph) and (pd.notna(row['Motivation'])):\n",
    "        topics = topic_extraction.extract_topics(str(row['Motivation']), num_topics=1, num_words=5)\n",
    "        for idx, topic in enumerate(topics):\n",
    "            graph.add((nobel, NO.hasMotivationTopics, Literal(','.join(topic), datatype=XSD.string)))\n",
    "    \n",
    "    # handle Laureate Type\n",
    "    if row['Laureate Type'] == 'Organization':\n",
    "        (org_name, uri_org_name) = normalize_name(str(row['Full Name']))\n",
    "        laureate = URIRef(NO[uri_org_name])\n",
    "        graph.add((laureate, RDF.type, FOAF.Organization))\n",
    "        graph.add((laureate, FOAF.name, Literal(org_name, datatype=XSD.string)))\n",
    "    elif row['Laureate Type'] == 'Individual':\n",
    "        laureate = URIRef(NO[str(row['Laureate ID'])]) # the URI will be nobelNamespace + Laureate ID\n",
    "        graph.add((laureate, RDF.type, FOAF.Person))\n",
    "        graph.add((laureate, FOAF.name, Literal(row['Full Name'], datatype=XSD.string)))\n",
    "        graph.add((laureate, FOAF.gender, Literal(row['Sex'], datatype=XSD.string)))\n",
    "\n",
    "    graph.add((laureate, RDF.type, NO.Laureate))\n",
    "    \n",
    "    if pd.notna(row['Birth Date']):\n",
    "        try:\n",
    "            datetime.datetime.strptime(str(row['Birth Date']), '%Y-%m-%d')\n",
    "            graph.add((laureate, NO.birthDate, Literal(row['Birth Date'], datatype=XSD.date)))\n",
    "        except ValueError:\n",
    "            splitted_date = str(row['Birth Date']).split('-')\n",
    "            new_date = splitted_date[0] + '-01-01'\n",
    "            print('Wrong Birth Date format in {}. The new date will be {}'.format(laureate, new_date))\n",
    "            graph.add((laureate, NO.birthDate, Literal(new_date, datatype=XSD.date)))\n",
    "\n",
    "    if pd.notna(row['Death Date']):\n",
    "        try:\n",
    "            datetime.datetime.strptime(str(row['Death Date']), '%Y-%m-%d')\n",
    "            graph.add((laureate, NO.deathDate, Literal(row['Death Date'], datatype=XSD.date)))\n",
    "        except ValueError:\n",
    "            splitted_date = str(row['Death Date']).split('-')\n",
    "            new_date = splitted_date[0] + '-01-01'\n",
    "            print('Wrong Death Date format in {}. The new date will be {}'.format(laureate, new_date))\n",
    "            graph.add((laureate, NO.deathDate, Literal(new_date, datatype=XSD.date)))\n",
    "\n",
    "    # handle birth city\n",
    "    if pd.notna(row['Birth City']):\n",
    "        birth_city = handle_city(str(row['Birth City']))\n",
    "        graph.add((laureate, NO.bornIn, birth_city))\n",
    "\n",
    "    # handle birth city country\n",
    "    if pd.notna(row['Birth Country']):\n",
    "        qres = handle_city_country(str(row['Birth Country']))\n",
    "        if (qres is not None) and ((birth_city, NO.locatedIn, JUR.Country) not in graph): # new locatedIn\n",
    "            graph.add((birth_city, NO.locatedIn, next(iter(qres)).country)) # only the first match\n",
    "\n",
    "    # handle death city\n",
    "    if pd.notna(row['Death City']):\n",
    "        death_city = handle_city(str(row['Death City']))\n",
    "        graph.add((laureate, NO.diedIn, death_city))\n",
    "\n",
    "    # handle death city country\n",
    "    if pd.notna(row['Death Country']):\n",
    "        qres = handle_city_country(str(row['Death Country']))\n",
    "        if (qres is not None) and ((death_city, NO.locatedIn, JUR.Country) not in graph): # new locatedIn\n",
    "            graph.add((death_city, NO.locatedIn, next(iter(qres)).country)) # only the first match\n",
    "\n",
    "    # handle organization\n",
    "    if pd.notna(row['Organization Name']):\n",
    "        org = handle_org(str(row['Organization Name']))\n",
    "        graph.add((laureate, NO.worksFor, org))\n",
    "\n",
    "        if pd.notna(row['Organization City']):\n",
    "            org_city = handle_city(str(row['Organization City']))\n",
    "            graph.add((org, NO.basedIn, org_city))\n",
    "\n",
    "        if pd.notna(row['Organization Country']):\n",
    "            qres = handle_city_country(str(row['Organization Country']))\n",
    "            if (qres is not None) and ((org_city, NO.locatedIn, JUR.Country) not in graph): # new locatedIn\n",
    "                graph.add((org_city, NO.locatedIn, next(iter(qres)).country)) # only the first match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60a769-2771-40c0-b745-5eec80381c80",
   "metadata": {},
   "source": [
    "## Fix laureate type errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83e65f-e5db-49d3-8239-0396c6407cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p, o in graph.triples((None, RDF.type, FOAF.Organization)):\n",
    "    if ((s, NO.bornIn, None)) in graph:\n",
    "        graph.add((s, RDF.type, FOAF.Person))\n",
    "        graph.remove((s, RDF.type, FOAF.Organization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e99100",
   "metadata": {},
   "source": [
    "## Populate the graph with journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in journals.iterrows():\n",
    "    journal = URIRef(NO[row['Title'].replace(\" \", \"_\")])\n",
    "    graph.add((journal, RDF.type, NO.Journal))\n",
    "    graph.add((journal, NO.hasTitle, row['Title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec253baa-96c4-4cf8-9903-c049674704aa",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a02d53-86e9-45c0-8156-dc85fdad578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.ttl', 'w', encoding='utf-8') as out:\n",
    "    out.write(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bd140a-8535-4b6f-ac90-cb3166cde70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
